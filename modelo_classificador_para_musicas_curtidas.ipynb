{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Template — MVP: *Machine Learning & Analytics*\n",
        "**Autor:** Rafael Theodoro Rocha  \n",
        "\n",
        "**Data:** 28/09/2025\n",
        "\n",
        "**Matrícula:** 4052025001358\n",
        "\n",
        "**Dataset:** Ex: [Iris Dataset](https://archive.ics.uci.edu/dataset/53/iris)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "kpRC005s2jqm"
      },
      "id": "kpRC005s2jqm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ✅ Checklist do MVP (o que precisa conter)\n",
        "- [✅] **Problema definido** e contexto de negócio\n",
        "- [✅] **Carga e preparação** dos dados (sem vazamento de dados)\n",
        "- [✅] **Divisão** em treino/validação/teste (ou validação cruzada apropriada)\n",
        "- [✅] **Tratamento**: limpeza, transformação e **engenharia de atributos**\n",
        "- [✅] **Modelagem**: comparar abordagens/modelos (com **baseline**)\n",
        "- [✅] **Otimização de hiperparâmetros**\n",
        "- [✅] **Avaliação** com **métricas adequadas** e discussão de limitações\n",
        "- [✅] **Boas práticas**: seeds fixas, tempo de treino, recursos computacionais, documentação\n",
        "- [✅] **Pipelines reprodutíveis** (sempre que possível)"
      ],
      "metadata": {
        "id": "VGVExhAf27AS"
      },
      "id": "VGVExhAf27AS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Escopo, Objetivo e Definição do Problema\n",
        "\n",
        "## Contexto e Objetivo\n",
        "O objetivo do projeto é **prever se um usuário irá curtir uma música** com base em características da faixa (ex.: `danceability`, `energy`, `year`, `acousticness`).  \n",
        "A previsão permite personalizar recomendações musicais e melhorar a experiência do usuário, priorizando músicas que ele tem maior probabilidade de gostar.\n",
        "\n",
        "## Tipo de Tarefa\n",
        "- **Classificação binária**: a variável alvo é `liked` (1 = curtida, 0 = não curtida).\n",
        "\n",
        "## Área de Aplicação\n",
        "- Dados tabulares provenientes de músicas e comportamento do usuário.\n",
        "- Aplicação em **recomendação musical**, análise de preferências e personalização de playlists.\n",
        "\n",
        "## Valor para o Negócio / Usuário\n",
        "- Identificar músicas que o usuário realmente irá curtir, aumentando **engajamento e satisfação**.\n",
        "- Permitir **personalização de playlists** e **ranking refinado de recomendações**.\n",
        "- Possibilitar futuras evoluções do sistema, combinando classificação com **modelos probabilísticos** e **clustering de estilos musicais** para recomendações híbridas.\n"
      ],
      "metadata": {
        "id": "yjREqZ4e3-Hh"
      },
      "id": "yjREqZ4e3-Hh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Reprodutibilidade e ambiente"
      ],
      "metadata": {
        "id": "CQdmS06j4_mn"
      },
      "id": "CQdmS06j4_mn"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Setup básico e reprodutibilidade ===\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Seed global:\", SEED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmyeSLND4ANa",
        "outputId": "9ddc12d1-926d-47af-990a-8a308b896249"
      },
      "id": "qmyeSLND4ANa",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11\n",
            "Seed global: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dpzW4yaJ7TzM"
      },
      "id": "dpzW4yaJ7TzM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Extração e Origem dos Dados\n",
        "\n",
        "**Versão:** 1.0\n",
        "\n",
        "Este projeto utiliza um modelo de **classificação supervisionada** para prever se uma música será curtida (`liked`) ou não, com base em suas características sonoras e metadados.\n",
        "\n",
        "## Fonte de Dados\n",
        "\n",
        "As músicas utilizadas para treinamento e avaliação do modelo foram coletadas a partir da biblioteca do usuário no Spotify, utilizando dois endpoints da API oficial do Spotify:\n",
        "\n",
        "- Músicas curtidas: `GET https://api.spotify.com/v1/me/tracks`\n",
        "- Músicas mais ouvidas: `GET https://api.spotify.com/v1/me/top/tracks`\n",
        "\n",
        "Os dados foram armazenados localmente em arquivos `.json` e processados para compor os datasets de entrada do modelo.  \n",
        "A documentação completa da API do Spotify está disponível em: https://developer.spotify.com/documentation/web-api\n",
        "\n",
        "## Features das Músicas\n",
        "\n",
        "Inicialmente, a extração de características sonoras das faixas (como `danceability`, `energy`, `valence`, etc.) seria realizada por meio dos endpoints:\n",
        "\n",
        "- Track's Audio Features: `GET https://api.spotify.com/v1/audio-features/{id}`  \n",
        "- Track's Audio Analysis: `GET https://api.spotify.com/v1/audio-analysis/{id}`\n",
        "\n",
        "Como estes endpoints foram oficialmente depreciados, optou-se por utilizar datasets públicos disponíveis no **Kaggle**, contendo as features previamente extraídas.  \n",
        "Esses dados foram cruzados com os dados das músicas do usuário para construir o dataset final.\n",
        "\n",
        "> **Observação:** Nem todas as músicas do usuário (curtidas ou mais ouvidas) estavam presentes nos datasets públicos, reduzindo o tamanho final do DataFrame para treinamento.\n",
        "\n",
        "## Dataset Consolidado\n",
        "\n",
        "Após o processamento, foi criado o DataFrame principal contendo:\n",
        "\n",
        "- Colunas de metadados (`track_name`, `artists`, `track_id`)  \n",
        "- Features numéricas para modelagem  \n",
        "- Variável alvo (`liked`), binária\n"
      ],
      "metadata": {
        "id": "7Fo4dXe77Uoz"
      },
      "id": "7Fo4dXe77Uoz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Extração das Músicas Curtidas e Mais Ouvidas\n",
        "\n",
        "**Versão:** 1.0\n",
        "\n",
        "Os dados das músicas do usuário foram extraídos em lotes da API do Spotify.\n",
        "\n",
        "## Extração de Músicas Curtidas (`/v1/me/tracks`)\n",
        "\n",
        "Os dados das músicas curtidas do usuário foram extraídos em lotes utilizando o endpoint `/v1/me/tracks` da API do Spotify, que retorna as faixas salvas na biblioteca do usuário.\n",
        "\n",
        "Os dados coletados foram armazenados localmente em arquivos `.json` paginados:\n",
        "\n",
        "```python\n",
        "arquivos_musicas_curtidas = [\n",
        "    \"musicas_curtidas-1-50.json\",\n",
        "    \"musicas_curtidas-51-100.json\",\n",
        "    \"musicas_curtidas-101-150.json\",\n",
        "    \"musicas_curtidas-151-200.json\",\n",
        "    \"musicas_curtidas-201-250.json\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "kAmja5N0760I"
      },
      "id": "kAmja5N0760I"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IbQVWueoX6U0"
      },
      "id": "IbQVWueoX6U0"
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/rafatheodoro/mvp-machine-learning/main/\"\n",
        "\n",
        "\n",
        "arquivos_musicas_curtidas = [\n",
        "    \"musicas_curtidas-1-50.json\",\n",
        "    \"musicas_curtidas-51-100.json\",\n",
        "    \"musicas_curtidas-101-150.json\",\n",
        "    \"musicas_curtidas-151-200.json\",\n",
        "    \"musicas_curtidas-201-250.json\"\n",
        "]\n",
        "\n",
        "# Monta a lista completa de URLs\n",
        "urls_musicas_curtidas = [base_url + nome for nome in arquivos_musicas_curtidas]\n",
        "\n",
        "def carregar_musicas_curtidas(urls_json):\n",
        "    todas_musicas = []\n",
        "    for url in urls_json:\n",
        "        response = requests.get(url)  # baixa o arquivo\n",
        "        response.raise_for_status()   # gera erro se a URL estiver inválida\n",
        "        data = response.json()        # carrega o JSON direto da URL\n",
        "        for item in data.get(\"items\", []):\n",
        "            track = item.get(\"track\")\n",
        "            if track:\n",
        "                todas_musicas.append(track)\n",
        "    return todas_musicas\n",
        "\n",
        "todas_musicas_curtidas = carregar_musicas_curtidas(urls_musicas_curtidas)\n",
        "\n",
        "# Extrai nome, ID, artistas, duração e popularidade das faixas\n",
        "def extrair_colunas_relevantes(tracks):\n",
        "    return pd.DataFrame([{\n",
        "        \"track_name\": track.get(\"name\"),\n",
        "        \"track_id\": track.get(\"id\"),\n",
        "        \"artists\": \", \".join([artist[\"name\"] for artist in track.get(\"artists\", [])]),\n",
        "        \"duration_ms\": track.get(\"duration_ms\"),\n",
        "        \"popularity\": track.get(\"popularity\")\n",
        "    } for track in tracks])\n",
        "\n",
        "df_musicas_curtidas = extrair_colunas_relevantes(todas_musicas_curtidas)\n",
        "\n",
        "df_musicas_curtidas.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hBkhqjc-7nq2",
        "outputId": "416afd42-5efb-4c66-8740-d9aba4dc0f4a"
      },
      "id": "hBkhqjc-7nq2",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       track_name                track_id           artists  duration_ms  \\\n",
              "0      In the End  60a0Rd6pjrkxjPbaKzXjfq       Linkin Park       216880   \n",
              "1  American Idiot  45zvStEMsXp8z45OQRhWFJ         Green Day       174320   \n",
              "2     All My Life  6tsojOQ5wHaIjKqIryLZK6      Foo Fighters       263440   \n",
              "3    Want You Bad  6hwQ69v7VbPhTTR2fOtYX7     The Offspring       202573   \n",
              "4      Chop Suey!  2DlHlPMa4M17kufBvI2lEN  System Of A Down       210240   \n",
              "\n",
              "   popularity  \n",
              "0          88  \n",
              "1          61  \n",
              "2          72  \n",
              "3          73  \n",
              "4          85  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1c9788e-9646-4664-b8c9-19bd7d4481ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_name</th>\n",
              "      <th>track_id</th>\n",
              "      <th>artists</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the End</td>\n",
              "      <td>60a0Rd6pjrkxjPbaKzXjfq</td>\n",
              "      <td>Linkin Park</td>\n",
              "      <td>216880</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>American Idiot</td>\n",
              "      <td>45zvStEMsXp8z45OQRhWFJ</td>\n",
              "      <td>Green Day</td>\n",
              "      <td>174320</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All My Life</td>\n",
              "      <td>6tsojOQ5wHaIjKqIryLZK6</td>\n",
              "      <td>Foo Fighters</td>\n",
              "      <td>263440</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Want You Bad</td>\n",
              "      <td>6hwQ69v7VbPhTTR2fOtYX7</td>\n",
              "      <td>The Offspring</td>\n",
              "      <td>202573</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chop Suey!</td>\n",
              "      <td>2DlHlPMa4M17kufBvI2lEN</td>\n",
              "      <td>System Of A Down</td>\n",
              "      <td>210240</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1c9788e-9646-4664-b8c9-19bd7d4481ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1c9788e-9646-4664-b8c9-19bd7d4481ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1c9788e-9646-4664-b8c9-19bd7d4481ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bd9e64dc-1873-40a3-ab50-9fe2d44df51c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd9e64dc-1873-40a3-ab50-9fe2d44df51c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bd9e64dc-1873-40a3-ab50-9fe2d44df51c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_musicas_curtidas",
              "summary": "{\n  \"name\": \"df_musicas_curtidas\",\n  \"rows\": 243,\n  \"fields\": [\n    {\n      \"column\": \"track_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 230,\n        \"samples\": [\n          \"Alegria Compartilhada\",\n          \"Don't You (Forget About Me)\",\n          \"Tom Sawyer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 231,\n        \"samples\": [\n          \"37CKvfJpbLhcK8USArso3m\",\n          \"5Y8Rj0s6wuM5DlQdllYiWl\",\n          \"3QZ7uX97s82HFYSmQUAN1D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"artists\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 86,\n        \"samples\": [\n          \"BRAZA\",\n          \"Linkin Park\",\n          \"Eric Clapton, Steve Winwood\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 134825,\n        \"min\": 114666,\n        \"max\": 1003066,\n        \"num_unique_values\": 231,\n        \"samples\": [\n          203373,\n          261239,\n          276880\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"popularity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 0,\n        \"max\": 88,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          85,\n          28,\n          76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extração de Músicas Mais Ouvidas (`/v1/me/top/tracks`)\n",
        "\n",
        "Os dados foram extraídos em lotes da API do Spotify utilizando o endpoint `/v1/me/top/tracks`, que retorna as músicas mais ouvidas pelo usuário autenticado.\n",
        "\n",
        "Os dados foram armazenados localmente em arquivos `.json` paginados:\n",
        "\n",
        "```python\n",
        "arquivos_musicas_ouvidas = [\n",
        "    \"musicas_ouvidas-1-50.json\",\n",
        "    \"musicas_ouvidas-51-100.json\",\n",
        "    \"musicas_ouvidas-101-150.json\",\n",
        "    \"musicas_ouvidas-151-200.json\",\n",
        "    \"musicas_ouvidas-201-250.json\",\n",
        "    \"musicas_ouvidas-251-300.json\",\n",
        "    \"musicas_ouvidas-301-350.json\",\n",
        "    \"musicas_ouvidas-351-400.json\",\n",
        "    \"musicas_ouvidas-401-450.json\",\n",
        "    \"musicas_ouvidas-451-500.json\",\n",
        "    \"musicas_ouvidas-501-550.json\"\n",
        "]\n",
        "\n",
        "Observação: Algumas músicas curtidas também estão presentes nesse conjunto. Portanto, para garantir o balanceamento entre músicas curtidas (liked = 1) e não curtidas (liked = 0), utilizou-se um conjunto maior de músicas ouvidas.\n",
        "Além disso, não foram encontradas features para todas as músicas curtidas e ouvidas do usuário, o que fez com que o dataset final (df_musicas) fosse reduzido."
      ],
      "metadata": {
        "id": "AUfgOZlx9-KW"
      },
      "id": "AUfgOZlx9-KW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Base URL correta\n",
        "base_url = \"https://raw.githubusercontent.com/rafatheodoro/mvp-machine-learning/main/\"\n",
        "\n",
        "# Arquivos das músicas ouvidas\n",
        "arquivos_musicas_ouvidas = [\n",
        "    \"musicas_ouvidas-1-50.json\",\n",
        "    \"musicas_ouvidas-51-100.json\",\n",
        "    \"musicas_ouvidas-101-150.json\",\n",
        "    \"musicas_ouvidas-151-200.json\",\n",
        "    \"musicas_ouvidas-201-250.json\",\n",
        "    \"musicas_ouvidas-251-300.json\",\n",
        "    \"musicas_ouvidas-301-350.json\",\n",
        "    \"musicas_ouvidas-351-400.json\",\n",
        "    \"musicas_ouvidas-401-450.json\",\n",
        "    \"musicas_ouvidas-451-500.json\",\n",
        "    \"musicas_ouvidas-551-600.json\",\n",
        "    \"musicas_ouvidas-601-650.json\",\n",
        "    \"musicas_ouvidas-651-700.json\"\n",
        "]\n",
        "\n",
        "# Monta as URLs\n",
        "urls_musicas_ouvidas = [base_url + nome for nome in arquivos_musicas_ouvidas]\n",
        "\n",
        "# Função para carregar músicas ouvidas\n",
        "def carregar_musicas_ouvidas(urls_json):\n",
        "    todas_musicas = []\n",
        "    for url in urls_json:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        for item in data.get(\"items\", []):\n",
        "            track = item.get(\"track\")\n",
        "            if track:\n",
        "                todas_musicas.append(track)\n",
        "    return todas_musicas\n",
        "\n",
        "# Carregar e processar músicas ouvidas\n",
        "todas_musicas_ouvidas = carregar_musicas_ouvidas(urls_musicas_ouvidas)\n",
        "df_musicas_ouvidas = extrair_colunas_relevantes(todas_musicas_ouvidas)\n",
        "\n",
        "df_musicas_ouvidas.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Jl8i9rBS-pF1",
        "outputId": "b8b1e25f-475a-4592-ba61-6a802bddd9f2"
      },
      "id": "Jl8i9rBS-pF1",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deb2565f-7ea7-4895-b322-ccd905184fa3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deb2565f-7ea7-4895-b322-ccd905184fa3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-deb2565f-7ea7-4895-b322-ccd905184fa3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-deb2565f-7ea7-4895-b322-ccd905184fa3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_musicas_ouvidas",
              "summary": "{\n  \"name\": \"df_musicas_ouvidas\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Montagem do DataFrame das Músicas com Rótulo (Target)\n",
        "\n",
        "Após a extração das músicas curtidas (`/v1/me/tracks`) e das músicas mais ouvidas (`/v1/me/top/tracks`), os dados foram organizados em dois dataframes:\n",
        "\n",
        "- `df_musicas_curtidas`: músicas curtidas (salvas) pelo usuário.  \n",
        "- `df_musicas_ouvidas`: músicas mais ouvidas pelo usuário.\n",
        "\n",
        "Para treinar o modelo de classificação supervisionado, foi criada a variável alvo `liked`, que indica se uma música foi curtida (`liked = 1`) ou não (`liked = 0`).  \n",
        "Essa coluna será utilizada como **target** no treinamento do modelo.\n",
        "\n",
        "Os dois conjuntos foram então combinados no dataframe `df_musicas`, que contém as seguintes colunas:\n",
        "\n",
        "- `track_id`  \n",
        "- `track_name`  \n",
        "- `artists`  \n",
        "- `duration_ms`  \n",
        "- `popularity`  \n",
        "- `liked` (variável alvo)\n"
      ],
      "metadata": {
        "id": "AzjXZXUs-xP6"
      },
      "id": "AzjXZXUs-xP6"
    },
    {
      "cell_type": "code",
      "source": [
        "df_musicas_curtidas['liked'] = 1  # Curtidas (liked = 1)\n",
        "df_musicas_ouvidas['liked'] = 0   # Apenas ouvidas (liked = 0)\n",
        "\n",
        "df_musicas = pd.concat(\n",
        "    [df_musicas_curtidas, df_musicas_ouvidas],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# Mantém a versão 'curtida' (liked=1), se a música estiver duplicada\n",
        "df_musicas = (\n",
        "    df_musicas\n",
        "    .sort_values(\"liked\", ascending=False)  # Garante que liked=1 venha primeiro\n",
        "    .drop_duplicates(subset=[\"track_id\"], keep=\"first\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Distribuição da váriavel alvo (liked)\n",
        "df_musicas['liked'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "ulErE7Y9_JnO",
        "outputId": "799bca78-91b3-49c0-e7d8-917aec186f98"
      },
      "id": "ulErE7Y9_JnO",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "liked\n",
              "1    231\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>liked</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Enriquecimento com Audio Features\n",
        "\n",
        "Para enriquecer o dataset com características de áudio das músicas curtidas e ouvidas, foram utilizados diversos datasets públicos do Kaggle. Isso foi necessário porque os endpoints da API do Spotify que forneciam essas informações foram descontinuados.\n",
        "\n",
        "## Datasets utilizados\n",
        "\n",
        "Foram utilizados os seguintes arquivos CSV como fontes complementares de dados:\n",
        "\n",
        "| Dataset                  | Descrição                                  |\n",
        "|--------------------------|--------------------------------------------|\n",
        "| `tracks_features.csv`     | Contém features de faixas diversas.        |\n",
        "| `ultimateClassicRock.csv` | Contém features de faixas de rock clássico.|\n",
        "| `spotify-1990.csv`        | Contém features de faixas lançadas nos anos 1990. |\n",
        "| `spotify-2000.csv`        | Contém features de faixas lançadas nos anos 2000. |\n",
        "| `audioFeatures.csv`       | Contém features de faixas diversas.       |\n",
        "\n",
        "## Tratamentos realizados\n",
        "\n",
        "Como os datasets foram extraídos de fontes distintas, foi necessário realizar padronizações antes da junção com o dataset principal:\n",
        "\n",
        "- Normalização dos nomes de colunas para letras minúsculas  \n",
        "- Renomeação de colunas para unificação:  \n",
        "  - `id` → `track_id`  \n",
        "  - `artist` / `artist_name` → `artists`  \n",
        "  - `title` / `track` / `name` → `track_name`  \n",
        "- Junção dos dados com o dataframe `df_musicas`, utilizando as colunas disponíveis para garantir o máximo de correspondência\n",
        "\n",
        "## Dataset final com audio features\n",
        "\n",
        "Os dados foram consolidados no dataframe:\n",
        "\n",
        "```python\n",
        "df_musicas_features\n"
      ],
      "metadata": {
        "id": "_1azSKfU_KwA"
      },
      "id": "_1azSKfU_KwA"
    },
    {
      "cell_type": "code",
      "source": [
        "# URLs raw dos CSVs no GitHub\n",
        "url_track_features = \"https://raw.githubusercontent.com/rafatheodoro/mvp-machine-learning/main/tracks_feature_merged.csv\"\n",
        "url_features_rock = \"https://raw.githubusercontent.com/rafatheodoro/mvp-machine-learning/main/ultimateClassicRock.csv\"\n",
        "url_features_1990 = \"https://raw.githubusercontent.com/rafatheodoro/mvp-machine-learning/main/spotify-1990.csv\"\n",
        "url_features_2000 = \"https://raw.githubusercontent.com/rafatheodoro/mvp-machine-learning/main/spotify-2000.csv\"\n",
        "\n",
        "\n",
        "# Leitura e padronização dos datasets\n",
        "df_track_features = pd.read_csv(url_track_features)\n",
        "df_track_features.columns = df_track_features.columns.str.lower()\n",
        "df_track_features.rename(columns={'id':'track_id', 'name': 'track_name'}, inplace=True)\n",
        "\n",
        "# Merge com df_musicas (assumindo df_musicas já carregado)\n",
        "df_features_merged_musicas = pd.merge(\n",
        "    df_track_features,\n",
        "    df_musicas[['track_id', 'liked']],\n",
        "    on='track_id',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Leitura e padronização de outros datasets\n",
        "df_features_rock = pd.read_csv(url_features_rock)\n",
        "df_features_rock.columns = df_features_rock.columns.str.lower()\n",
        "df_features_rock.rename(columns={'track': 'track_name', 'artist': 'artists'}, inplace=True)\n",
        "\n",
        "df_features_1990 = pd.read_csv(url_features_1990)\n",
        "df_features_1990.columns = df_features_1990.columns.str.lower()\n",
        "df_features_1990.rename(columns={'track': 'track_name', 'artist': 'artists'}, inplace=True)\n",
        "\n",
        "df_features_2000 = pd.read_csv(url_features_2000)\n",
        "df_features_2000.columns = df_features_2000.columns.str.lower()\n",
        "df_features_2000.rename(columns={'title': 'track_name', 'artist': 'artists', 'loudness (db)': 'loudness'}, inplace=True)\n",
        "\n",
        "# Consolidação de todos os datasets e merge com df_musicas\n",
        "dfs_outras_features_merged_musicas = pd.concat([df_features_rock, df_features_1990, df_features_2000], ignore_index=True)\n",
        "dfs_outras_features_merged_musicas = pd.merge(\n",
        "    dfs_outras_features_merged_musicas,\n",
        "    df_musicas[['track_id', 'track_name', 'artists', 'liked']],\n",
        "    on=['track_name', 'artists'],\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Dataframe final para treinamento e teste\n",
        "df_musicas_features = pd.concat([df_features_merged_musicas, dfs_outras_features_merged_musicas], ignore_index=True)\n",
        "\n",
        "# Verificar distribuição da variável alvo\n",
        "print(df_musicas_features['liked'].value_counts())\n",
        "\n",
        "# Listar colunas do dataframe final\n",
        "print(df_musicas_features.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "P37n_p8y_mWR",
        "outputId": "315de692-0129-45af-e7a4-f14949c4d4f1"
      },
      "id": "P37n_p8y_mWR",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2448292620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Leitura e padronização dos datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_track_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_track_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_track_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_track_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_track_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'track_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'track_name'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Seleção das Features para o Modelo\n",
        "\n",
        "Para a construção do modelo preditivo, selecionamos um conjunto de variáveis numéricas que representam características relevantes das faixas de áudio, além de variáveis auxiliares para análise e identificação.  \n",
        "A variável alvo é **`liked`**, indicando se uma música foi curtida (`1`) ou não (`0`).\n",
        "\n",
        "As variáveis de identificação e rótulo incluem:\n",
        "\n",
        "- `track_id`: identificador único da música  \n",
        "- `track_name`: nome da música  \n",
        "- `artists`: artista(s) responsáveis pela música  \n",
        "- `liked`: variável **alvo** do modelo supervisionado (1 = curtida, 0 = não curtida)  \n",
        "\n",
        "As variáveis de áudio (features numéricas) selecionadas foram:\n",
        "\n",
        "- **acousticness**: grau de sonoridade acústica da música (0 a 1)  \n",
        "- **danceability**: quão dançável a música é (0 a 1)  \n",
        "- **energy**: intensidade e atividade da faixa (0 a 1)  \n",
        "- **liveness**: presença de público ao vivo (0 a 1)  \n",
        "- **loudness**: volume médio da música em decibéis (valores geralmente negativos)  \n",
        "- **speechiness**: presença de elementos falados na faixa (0 a 1)  \n",
        "- **valence**: positividade ou alegria percebida na música (0 a 1)  \n",
        "- **year**: ano de lançamento da música — pode capturar tendências temporais  \n",
        "\n",
        "💡 **Nota:** Todas as variáveis utilizadas são **numéricas e contínuas**, simplificando o pré-processamento, já que não há necessidade de codificação categórica.\n",
        "\n",
        "Durante a construção do modelo, foi realizada uma **seleção criteriosa** das variáveis, considerando relevância preditiva, consistência e tipo de informação representada.  \n",
        "\n",
        "As variáveis mantidas no modelo foram:\n",
        "\n",
        "- `acousticness`, `danceability`, `energy`, `liveness`, `loudness`, `speechiness`, `valence`, `year`  \n",
        "- Metadados: `track_id`, `track_name`, `artists`  \n",
        "- Variável alvo: `liked`  \n",
        "\n",
        "As variáveis removidas e justificativas:\n",
        "\n",
        "- **Gênero, popularidade e metadata**: `top genre`, `artist_ids`, `album_id`, `explicit`, `popularity`  \n",
        "  - Categorias inconsistentes ou externas, podendo introduzir viés  \n",
        "- **Tempo, duração e métricas relacionadas**: `duration_ms`, `duration`, `length (duration)`, `tempo`, `beats per minute (bpm)`, `time_signature`  \n",
        "  - Redundantes e de baixo poder discriminativo  \n",
        "- **Técnicas ou de baixa relevância**: `instrumentalness`, `key`, `mode`, `track_number`, `disc_number`, `release_date`  \n",
        "  - Pouco relacionadas à preferência do usuário ou substituídas por `year`  \n",
        "\n",
        "Após o merge e a seleção de features, o **DataFrame final** apresenta:\n",
        "\n",
        "- ✅ Nenhum valor ausente (*missing values*)  \n",
        "- ✅ Variáveis categóricas normalizadas  \n",
        "- ✅ Sem necessidade de limpeza adicional  \n",
        "\n",
        "Essas condições permitem um **pipeline de modelagem mais limpo e eficiente**.\n"
      ],
      "metadata": {
        "id": "tOlGdxeHBsIO"
      },
      "id": "tOlGdxeHBsIO"
    },
    {
      "cell_type": "code",
      "source": [
        "features_selecionadas = [\n",
        "    'track_id', 'artists', 'track_name', 'liked',\n",
        "    'acousticness', 'danceability', 'energy', 'liveness', 'loudness', 'speechiness', 'valence', 'year'\n",
        "]\n",
        "\n",
        "df_musicas_features = df_musicas_features[features_selecionadas]\n",
        "\n",
        "# Verificação final\n",
        "df_musicas_features.info()\n",
        "df_musicas_features['liked'].value_counts()"
      ],
      "metadata": {
        "id": "3gH7YiJFBxG9"
      },
      "id": "3gH7YiJFBxG9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Fase de Modelagem e Treino\n",
        "\n",
        "Nesta etapa, utilizamos as variáveis extraídas e tratadas para treinar um modelo de machine learning capaz de prever se uma música será **curtida** (`liked = 1`) ou **não curtida** (`liked = 0`), com base em suas características de áudio.\n",
        "\n",
        "Foram geradas **duas visões do dataset** para avaliar o impacto da variável temporal `year`:\n"
      ],
      "metadata": {
        "id": "1HluwJ_aB9Kx"
      },
      "id": "1HluwJ_aB9Kx"
    },
    {
      "cell_type": "code",
      "source": [
        "colunas_com_year = [\n",
        "    'acousticness', 'danceability', 'energy', 'liveness', 'loudness', 'speechiness', 'valence', 'year'\n",
        "]\n",
        "\n",
        "colunas_sem_year = [\n",
        "        'acousticness', 'danceability', 'energy', 'liveness', 'loudness', 'speechiness', 'valence'\n",
        "]\n",
        "\n",
        "# X e y para os dois cenários\n",
        "X_com_year = df_musicas_features[colunas_com_year]\n",
        "X_sem_year = df_musicas_features[colunas_sem_year]\n",
        "y = df_musicas_features['liked']\n",
        "\n",
        "df_musicas_features.info()"
      ],
      "metadata": {
        "id": "En-11QNjCFQg"
      },
      "id": "En-11QNjCFQg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divisão entre Treino e Teste\n",
        "\n",
        "Foi adotada a estratégia padrão de separar 80% dos dados para treino e 20% para teste, mantendo a proporção da variável alvo (stratify=y).\n"
      ],
      "metadata": {
        "id": "Pr-A8BZ8CUxc"
      },
      "id": "Pr-A8BZ8CUxc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Com 'year'\n",
        "X_train_year, X_test_year, y_train_year, y_test_year = train_test_split(\n",
        "    X_com_year, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Sem 'year'\n",
        "X_train_no_year, X_test_no_year, y_train_no_year, y_test_no_year = train_test_split(\n",
        "    X_sem_year, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "k4mplpTzCYql"
      },
      "id": "k4mplpTzCYql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seleção de Modelos de Classificação e Treinamento\n",
        "\n",
        "| Modelo                  | Tipo                        | Motivo da Escolha |\n",
        "|-------------------------|----------------------------|-----------------|\n",
        "| Logistic Regression     | Linear, classificação binária | Simples, interpretável, serve como baseline. Funciona bem com features numéricas contínuas. |\n",
        "| Random Forest           | Ensemble de árvores (Bagging) | Captura relações não lineares, robusto a ruído, permite avaliar importância das features. |\n",
        "| XGBoost                 | Gradient Boosting sobre árvores | Modelo avançado, alto desempenho, otimiza erros sequencialmente, bom para métricas como F1-score. |\n",
        "\n",
        "> A combinação permite comparar desempenho de modelos simples e complexos e verificar se variáveis como `year` melhoram a predição.\n"
      ],
      "metadata": {
        "id": "ULY1_YRPCi6A"
      },
      "id": "ULY1_YRPCi6A"
    },
    {
      "cell_type": "code",
      "source": [
        "modelos = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "def treinar_modelo(modelo, X_train, y_train, X_test):\n",
        "\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    y_probs = modelo.predict_proba(X_test)[:, 1] if hasattr(modelo, \"predict_proba\") else None\n",
        "\n",
        "    return y_pred, y_probs\n",
        "\n",
        "#===============================\n",
        "# Logistic Regression\n",
        "# ================================\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "y_pred_lr_year, y_probs_lr_year = treinar_modelo(lr, X_train_year, y_train_year, X_test_year)\n",
        "y_pred_lr_no_year, y_probs_lr_no_year = treinar_modelo(lr, X_train_no_year, y_train_no_year, X_test_no_year)\n",
        "\n",
        "# ================================\n",
        "# Random Forest\n",
        "# ================================\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "\n",
        "y_pred_rf_year, y_probs_rf_year = treinar_modelo(rf, X_train_year, y_train_year, X_test_year)\n",
        "y_pred_rf_no_year, y_probs_rf_no_year = treinar_modelo(rf, X_train_no_year, y_train_no_year, X_test_no_year)\n",
        "\n",
        "# ================================\n",
        "# XGBoost\n",
        "# ================================\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "y_pred_xgb_year, y_probs_xgb_year = treinar_modelo(xgb, X_train_year, y_train_year, X_test_year)\n",
        "y_pred_xgb_no_year, y_probs_xgb_no_year = treinar_modelo(xgb, X_train_no_year, y_train_no_year, X_test_no_year)\n"
      ],
      "metadata": {
        "id": "eC6Im-moCiMz"
      },
      "id": "eC6Im-moCiMz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação do Modelo\n",
        "\n",
        "A função `avaliar_modelo_completo` avalia modelos de **classificação binária** (0 = não curtida, 1 = curtida) combinando **visualizações e métricas quantitativas**.\n",
        "\n",
        "### Métricas Escolhidas\n",
        "- **Matriz de Confusão:** identifica acertos e erros por classe.  \n",
        "- **Precision (classe positiva):** proporção de curtidas corretamente previstas, evitando falsos positivos.  \n",
        "- **Recall (classe positiva):** proporção de curtidas reais capturadas, garantindo cobertura.  \n",
        "- **F1-score:** balanceia precision e recall.  \n",
        "- **Accuracy:** acurácia geral do modelo.\n",
        "\n",
        "> Essas métricas permitem comparar desempenho, avaliar a capacidade de prever curtidas e analisar o impacto de diferentes features, como `year`.\n"
      ],
      "metadata": {
        "id": "GiX1ReGZDBUa"
      },
      "id": "GiX1ReGZDBUa"
    },
    {
      "cell_type": "code",
      "source": [
        "def avaliar_modelo(y_test, y_pred, label):\n",
        "    print(f\"\\n=== Avaliação {label} ===\")\n",
        "\n",
        "    # --- Matriz de Confusão ---\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cm_df = pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"Real 0 (não curtida)\", \"Real 1 (curtida)\"],\n",
        "        columns=[\"Predito 0\", \"Predito 1\"]\n",
        "    )\n",
        "    print(\"\\n📌 Matriz de Confusão:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    # --- Relatório de Classificação ---\n",
        "    print(\"\\n📌 Relatório de Classificação:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"Não curtida\", \"Curtida\"]))\n",
        "\n",
        "    # --- Heatmap ---\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=[\"Predito 0\", \"Predito 1\"],\n",
        "                yticklabels=[\"Real 0 (não curtida)\", \"Real 1 (curtida)\"])\n",
        "    plt.title(f\"Matriz de Confusão - {label}\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.xlabel(\"Predito\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Métricas principais ---\n",
        "    report_dict = classification_report(y_test, y_pred, output_dict=True, labels=[0, 1])\n",
        "\n",
        "    # Acessa a classe positiva independentemente do tipo da chave (str ou int)\n",
        "    if \"1\" in report_dict:\n",
        "        positive_key = \"1\"\n",
        "    else:\n",
        "        positive_key = 1\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"f1_score\": f1_score(y_test, y_pred),\n",
        "        \"precision_1\": report_dict[\"1\"][\"precision\"],  # classe positiva = 1 (Curtida)\n",
        "        \"recall_1\": report_dict[\"1\"][\"recall\"]\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "LQG2Dgr7DGPN"
      },
      "id": "LQG2Dgr7DGPN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Avaliação de todos os modelos COM year\n",
        "# ================================\n",
        "metrics_year = {}\n",
        "\n",
        "# Logistic Regression\n",
        "metrics_year[\"Logistic Regression\"] = avaliar_modelo(\n",
        "    y_test_year, y_pred_lr_year, \"Logistic Regression COM year\"\n",
        ")\n",
        "\n",
        "# Random Forest\n",
        "metrics_year[\"Random Forest\"] = avaliar_modelo(\n",
        "    y_test_year, y_pred_rf_year, \"Random Forest COM year\"\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "metrics_year[\"XGBoost\"] = avaliar_modelo(\n",
        "    y_test_year, y_pred_xgb_year, \"XGBoost COM year\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# Avaliação de todos os modelos SEM year\n",
        "# ================================\n",
        "metrics_no_year = {}\n",
        "\n",
        "# Logistic Regression\n",
        "metrics_no_year[\"Logistic Regression\"] = avaliar_modelo(\n",
        "    y_test_no_year, y_pred_lr_no_year, \"Logistic Regression SEM year\"\n",
        ")\n",
        "\n",
        "# Random Forest\n",
        "metrics_no_year[\"Random Forest\"] = avaliar_modelo(\n",
        "    y_test_no_year, y_pred_rf_no_year, \"Random Forest SEM year\"\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "metrics_no_year[\"XGBoost\"] = avaliar_modelo(\n",
        "    y_test_no_year, y_pred_xgb_no_year, \"XGBoost SEM year\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# Criar tabelas resumidas para comparação\n",
        "# ================================\n",
        "df_comparacao_year = pd.DataFrame(metrics_year).T\n",
        "df_comparacao_no_year = pd.DataFrame(metrics_no_year).T\n",
        "\n",
        "print(\"\\n--- Comparação COM year ---\")\n",
        "display(df_comparacao_year)\n",
        "\n",
        "print(\"\\n--- Comparação SEM year ---\")\n",
        "display(df_comparacao_no_year)\n"
      ],
      "metadata": {
        "id": "5L3m4R7oDKsz"
      },
      "id": "5L3m4R7oDKsz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparação com Modelo que Inclui a feature `year`\n",
        "\n",
        "| Modelo               | Accuracy | F1-score | Precision | Recall |\n",
        "|----------------------|----------|----------|-----------|--------|\n",
        "| Logistic Regression  | 0.609    | 0.609    | 0.609     | 0.609  |\n",
        "| Random Forest        | 0.587    | 0.612    | 0.577     | 0.652  |\n",
        "| XGBoost              | 0.587    | 0.642    | 0.567     | 0.739  |\n",
        "\n",
        "**Considerações:**\n",
        "\n",
        "- A inclusão da variável `year` trouxe **impacto positivo** para a predição.  \n",
        "- O `year` foi utilizado em sua **escala original** (ex.: 2000, 2010), sem normalização.  \n",
        "  - Isso não afeta modelos baseados em árvores (Random Forest, XGBoost).  \n",
        "  - Pode influenciar modelos lineares como a Regressão Logística, indicando oportunidade de **reteste** com a variável normalizada ou padronizada.  \n",
        "\n",
        "**Melhor Modelo observado:**\n",
        "\n",
        "- O modelo **XGBoost** apresentou os melhores resultados, com **maior recall (0.739)** e **F1-score (0.642)**.  \n",
        "- Como modelo de boosting, o XGBoost captura **padrões complexos**, incluindo:  \n",
        "  - **Interações entre variáveis** (ex.: `danceability + energy + year`)  \n",
        "  - **Relações não lineares**  \n",
        "  - **Ajuste dinâmico aos erros**, pois cada árvore aprende com os erros das anteriores.\n"
      ],
      "metadata": {
        "id": "xheRADBiDgdA"
      },
      "id": "xheRADBiDgdA"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4cw1kB6eCZ-1"
      },
      "id": "4cw1kB6eCZ-1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Melhorias no Treinamento dos Modelos\n",
        "\n",
        "Nesta etapa, aplicamos ajustes importantes para aprimorar o desempenho dos modelos na predição de músicas curtidas (`liked`).\n",
        "\n",
        "---\n",
        "\n",
        "## Normalização da variável `year`\n",
        "\n",
        "- A variável `year` foi utilizada anteriormente em sua escala original (ex.: 2000, 2010), o que pode impactar modelos lineares como a **Regressão Logística**.  \n",
        "- Para aumentar a eficiência do modelo linear, realizamos a **normalização** da variável `year`, garantindo que todos os atributos tenham escala compatível.\n",
        "\n",
        "---\n",
        "\n",
        "## Ajuste de Hiperparâmetros via GridSearchCV\n",
        "\n",
        "- Para cada modelo, foi definido um **grid de hiperparâmetros**:\n",
        "  - **Logistic Regression:** diferentes valores de `C` para regularização.\n",
        "  - **Random Forest:** número de estimadores, profundidade máxima, `min_samples_split` e `min_samples_leaf`.\n",
        "  - **XGBoost:** número de estimadores, profundidade das árvores, taxa de aprendizado (`learning_rate`) e `subsample`.\n",
        "- A busca foi realizada usando **GridSearchCV** com **5 folds estratificados**, garantindo:\n",
        "  - Melhor combinação de hiperparâmetros focada no **F1-score**.\n",
        "  - Validação consistente mesmo com pequenas diferenças na proporção de classes.\n",
        "\n",
        "---\n",
        "\n",
        "## Reuso da função `avaliar_modelo`\n",
        "\n",
        "- Função utilizada para gerar **matriz de confusão**, **relatório de classificação** e extrair métricas principais (accuracy, F1, precision e recall) para todos os modelos.\n",
        "\n",
        "---\n",
        "\n",
        "## Comparação final dos modelos\n",
        "\n",
        "- Após normalização do `year` e GridSearchCV, os modelos foram comparados em **accuracy** e **F1-score**, permitindo avaliar o impacto das melhorias no desempenho.\n"
      ],
      "metadata": {
        "id": "UrO3iXJIELh9"
      },
      "id": "UrO3iXJIELh9"
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# Normalização da variável 'year'\n",
        "# ======================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train_year.copy()\n",
        "X_test_scaled = X_test_year.copy()\n",
        "\n",
        "# Aplica a normalização apenas na coluna 'year'\n",
        "X_train_scaled[['year']] = scaler.fit_transform(X_train_year[['year']])\n",
        "X_test_scaled[['year']] = scaler.transform(X_test_year[['year']])\n",
        "\n",
        "# ======================================\n",
        "# Configuração de Validação Cruzada\n",
        "# ======================================\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ======================================\n",
        "# Grid de Hiperparâmetros\n",
        "# ======================================\n",
        "param_grid_lr = {\n",
        "    \"C\": [0.01, 0.1, 1, 10],       # regularização\n",
        "    \"penalty\": [\"l2\"],             # l2 é padrão\n",
        "    \"solver\": [\"lbfgs\"]\n",
        "}\n",
        "\n",
        "param_grid_rf = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [None, 5, 10],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "    \"min_samples_leaf\": [1, 2]\n",
        "}\n",
        "\n",
        "param_grid_xgb = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1],\n",
        "    \"subsample\": [0.7, 1.0]\n",
        "}\n",
        "\n",
        "# ======================================\n",
        "# Função auxiliar para GridSearch + Avaliação\n",
        "# ======================================\n",
        "def grid_search_avaliacao(modelo, param_grid, X_train, y_train, X_test, y_test, label):\n",
        "    grid = GridSearchCV(modelo, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"\\nMelhores parâmetros para {label}: {grid.best_params_}\")\n",
        "\n",
        "    y_pred_train = grid.predict(X_train)\n",
        "\n",
        "    y_pred = grid.predict(X_test)\n",
        "    metrics = avaliar_modelo(y_test, y_pred, label)\n",
        "\n",
        "    return grid.best_estimator_, metrics, y_pred, y_pred_train\n",
        "\n",
        "# ======================================\n",
        "# Treino e Avaliação COM 'year' normalizado\n",
        "# ======================================\n",
        "\n",
        "# Logistic Regression\n",
        "lr_best, metrics_lr, y_pred_lr, y_pred_train_lr  = grid_search_avaliacao(\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    param_grid_lr,\n",
        "    X_train_scaled, y_train_year,\n",
        "    X_test_scaled, y_test_year,\n",
        "    \"Logistic Regression COM year\"\n",
        ")\n",
        "\n",
        "# Random Forest\n",
        "rf_best, metrics_rf, y_pred_rf, y_pred_train_rf = grid_search_avaliacao(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid_rf,\n",
        "    X_train_year, y_train_year,\n",
        "    X_test_year, y_test_year,\n",
        "    \"Random Forest COM year\"\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "xgb_best, metrics_xgb, y_pred_xgb, y_pred_train_xgb = grid_search_avaliacao(\n",
        "    XGBClassifier(eval_metric='logloss', random_state=42),\n",
        "    param_grid_xgb,\n",
        "    X_train_year, y_train_year,\n",
        "    X_test_year, y_test_year,\n",
        "    \"XGBoost COM year\"\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# Comparação resumida\n",
        "# ======================================\n",
        "df_comparacacao_final = pd.DataFrame([metrics_lr, metrics_rf, metrics_xgb],\n",
        "                             index=[\"Logistic Regression\", \"Random Forest\", \"XGBoost\"])\n",
        "print(\"\\n--- Comparação Final dos Modelos (com variável 'year' e GridSearchCV) ---\")\n",
        "print(df_comparacacao_final)\n"
      ],
      "metadata": {
        "id": "np5KVu0MEdqX"
      },
      "id": "np5KVu0MEdqX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Análise final e Definição do Modelo\n",
        "\n",
        "Após comparação entre **Logistic Regression**, **Random Forest** e **XGBoost**, considerando ajustes de **hiperparâmetros**, **validação cruzada** e **normalização da variável `year`**, o **XGBoost** se destacou como o modelo mais adequado para prever curtidas em músicas.\n",
        "\n",
        "## Observações importantes\n",
        "\n",
        "- A **normalização da variável `year`** beneficiou principalmente a Logistic Regression, tornando os coeficientes mais interpretáveis.  \n",
        "- Mesmo após **GridSearchCV e normalização**, **Logistic Regression** e **Random Forest** não apresentaram melhorias significativas, mostrando que essas técnicas não impactaram tanto nesses modelos.  \n",
        "- O **XGBoost**, por outro lado, apresentou melhorias consistentes, consolidando-se como o melhor modelo para prever curtidas em músicas.\n",
        "\n",
        "## Métricas de Desempenho (após ajustes)\n",
        "\n",
        "| Modelo             | Accuracy | F1-score | Recall | Precision |\n",
        "|------------------|---------|----------|--------|-----------|\n",
        "| Logistic Regression | 0.609   | 0.609    | 0.609  | 0.609     |\n",
        "| Random Forest       | 0.609   | 0.608    | 0.652  | 0.577     |\n",
        "| XGBoost             | 0.565   | 0.615    | 0.739  | 0.567     |\n",
        "\n",
        "- **Recall elevado (0.739) do XGBoost:** captura a maior parte das músicas realmente curtidas (verdadeiros positivos).  \n",
        "- **F1-score (0.615) do XGBoost:** equilíbrio entre precisão e recall, mostrando boa capacidade de classificação mesmo com alguns falsos positivos.  \n",
        "- **Precision menor (0.567) do XGBoost:** indica a presença de falsos positivos, mas o foco é priorizar a identificação de músicas que o usuário realmente curtirá.\n",
        "\n",
        "## Justificativa do desempenho do XGBoost\n",
        "\n",
        "- **Boosting sequencial:** combina várias árvores fracas, aprendendo com os erros anteriores.  \n",
        "- **Captura padrões complexos:**  \n",
        "  - **Interações entre variáveis** (ex.: `danceability + energy + year`).  \n",
        "  - **Relações não lineares** entre features e curtidas.  \n",
        "  - **Ajuste dinâmico aos erros:** cada árvore corrige erros anteriores, aumentando recall e F1-score.  \n",
        "- **Validação cruzada estratificada:** garante avaliação robusta mesmo com dataset pequeno (~200 registros).  \n",
        "- **Ajuste de hiperparâmetros:** GridSearchCV otimiza `n_estimators`, `max_depth`, `learning_rate` e `subsample`.\n",
        "\n",
        "> Conclusão: O XGBoost apresentou **maior capacidade de identificar verdadeiros positivos**, sendo o modelo mais robusto para classificação de músicas curtidas.\n"
      ],
      "metadata": {
        "id": "eq5pTsrsEeht"
      },
      "id": "eq5pTsrsEeht"
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= Print do Resultado =======\n",
        "print(\"Resultado final do Treino e Teste do modelo XGBoost\")\n",
        "\n",
        "# ======= Treino =======\n",
        "df_train = pd.DataFrame({\n",
        "    \"track_id\": X_train_year.index,\n",
        "    \"real\": y_train_year.values,\n",
        "    \"pred\": y_pred_train_xgb\n",
        "})\n",
        "df_train[\"acerto\"] = df_train[\"real\"] == df_train[\"pred\"]\n",
        "df_train[\"conjunto\"] = \"Treino\"\n",
        "\n",
        "# ======= Teste =======\n",
        "df_test = pd.DataFrame({\n",
        "    \"track_id\": X_test_year.index,\n",
        "    \"real\": y_test_year.values,\n",
        "    \"pred\": y_pred_xgb\n",
        "})\n",
        "df_test[\"acerto\"] = df_test[\"real\"] == df_test[\"pred\"]\n",
        "df_test[\"conjunto\"] = \"Teste\"\n",
        "\n",
        "# ======= Concatenar =======\n",
        "df_resultados = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "# ======= Plot =======\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.scatterplot(\n",
        "    data=df_resultados,\n",
        "    x=\"track_id\",\n",
        "    y=\"real\",\n",
        "    hue=\"acerto\",\n",
        "    style=\"conjunto\",\n",
        "    palette={True:\"green\", False:\"red\"},\n",
        "    s=100\n",
        ")\n",
        "plt.yticks([0,1], [\"Não Curtida\", \"Curtida\"])\n",
        "plt.xlabel(\"Músicas (track_id)\")\n",
        "plt.ylabel(\"Valor Real\")\n",
        "plt.title(\"Acertos (verde) e Erros (vermelho) do Modelo XGBoost - Treino e Teste\")\n",
        "plt.legend(title=\"Acerto / Conjunto\", loc=\"upper right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1f7qrlx5CUEV"
      },
      "id": "1f7qrlx5CUEV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Conclusões Finais sobre o Modelo de Classificação para Previsão de Músicas Curtidas\n",
        "\n",
        "Após a modelagem e avaliação com **Logistic Regression**, **Random Forest** e **XGBoost**, os principais insights são:\n",
        "\n",
        "## Desempenho para o Usuário Alvo\n",
        "- O modelo apresentou bom desempenho para o usuário analisado, com **gosto musical específico** (rock, blues e gêneros afins).  \n",
        "- As músicas de teste incluíram gêneros fora do histórico de curtidas do usuário, avaliando a capacidade de generalização.  \n",
        "- Resultado: alta acurácia nos **verdadeiros positivos**, identificando corretamente músicas realmente curtidas.\n",
        "\n",
        "## Limitações em Falsos Positivos\n",
        "- Em outros usuários ou contextos, fatores subjetivos (como humor ou momento) podem afetar a curtida.  \n",
        "- Consequentemente, surgem **falsos positivos**, músicas previstas como curtidas que na prática não foram.\n",
        "\n",
        "## Possibilidades de Evolução\n",
        "Para melhorar a assertividade e gerar recomendações mais precisas:  \n",
        "- Utilizar **modelo probabilístico** ao invés de classificação binária.  \n",
        "- Integrar **clustering de estilos musicais** para uma recomendação híbrida.  \n",
        "- Combinar a **probabilidade de curtida** com clusters para criar um **ranking personalizado**.\n",
        "\n",
        "> ✅ **Conclusão Geral:**  \n",
        "> O XGBoost, com ajuste de hiperparâmetros, validação cruzada e capacidade de capturar padrões complexos, mostrou-se o modelo mais robusto para identificar músicas curtidas pelo usuário-alvo, considerando limitações subjetivas nas preferências musicais.\n"
      ],
      "metadata": {
        "id": "Q1fShZ53GFGc"
      },
      "id": "Q1fShZ53GFGc"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5SxhXDpYFast"
      },
      "id": "5SxhXDpYFast"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5QYNZt2FF_k"
      },
      "id": "y5QYNZt2FF_k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b7mr7k0mCNSR"
      },
      "id": "b7mr7k0mCNSR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2JzlteTO_92T"
      },
      "id": "2JzlteTO_92T",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}